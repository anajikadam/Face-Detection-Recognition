{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae97cbb-369e-4690-853a-21ec02ad4bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2f992-9452-49ec-95d9-5de67dcb833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006bef1-62be-437e-8e14-661a7be843f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"Img/test23.jpg\"\n",
    "img_obj = load_image( path )\n",
    "img = img_obj\n",
    "mp_face_detection = mediapipe.solutions.face_detection\n",
    "face_detector =  mp_face_detection.FaceDetection( min_detection_confidence = 0.6)\n",
    "fd_results = face_detector.process(img)\n",
    "# fd_results.detections[0].face\n",
    "if len(fd_results.detections)>=1:\n",
    "    print(\"Selected Number of Faces:\", len(fd_results.detections))\n",
    "    face = fd_results.detections[0]\n",
    "    confidence = face.score[0]\n",
    "    print(\"Face confidence:\", confidence)\n",
    "    try:\n",
    "        landmarks = face.location_data.relative_keypoints\n",
    "        right_eye = (int(landmarks[0].x * img.shape[1]), int(landmarks[0].y * img.shape[0]))\n",
    "        left_eye = (int(landmarks[1].x * img.shape[1]), int(landmarks[1].y * img.shape[0]))\n",
    "        nose = (int(landmarks[2].x * img.shape[1]), int(landmarks[2].y * img.shape[0]))\n",
    "        mouth = (int(landmarks[3].x * img.shape[1]), int(landmarks[3].y * img.shape[0]))\n",
    "        print(right_eye, left_eye, nose, mouth)\n",
    "    except Exception as ex:\n",
    "        print( ex )\n",
    "            \n",
    "cv2.circle(img, right_eye, 1, (255, 0, 0), -1)\n",
    "cv2.circle(img, left_eye, 1, (255, 0, 0), -1)\n",
    "cv2.circle(img, nose, 7, (255, 0, 0), -1)\n",
    "cv2.circle(img, mouth, 7, (255, 0, 0), -1)\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80130bff-51ff-4e22-9b3a-23da0afdee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"Img/test23.jpg\"\n",
    "img_obj = load_image( path )\n",
    "img = img_obj\n",
    "# mp_face_detection = mediapipe.solutions.face_detection\n",
    "# face_detector =  mp_face_detection.FaceDetection( min_detection_confidence = 0.6)\n",
    "\n",
    "faceModule = mediapipe.solutions.face_mesh\n",
    "face_mesh = faceModule.FaceMesh(static_image_mode=True)\n",
    "\n",
    "results = face_mesh.process(img )\n",
    "landmarks = results.multi_face_landmarks[0]\n",
    "            \n",
    "facial_area_obj = faceModule.FACEMESH_RIGHT_EYE\n",
    "\n",
    "facial_area_obj = faceModule.FACEMESH_LEFT_EYE\n",
    "facial_area_obj = faceModule.FACEMESH_FACE_OVAL\n",
    "# facial_area_obj = faceModule.FACEMESH_NOSE\n",
    "# facial_area_obj = faceModule.FACEMESH_LIPS\n",
    "\n",
    "for source_idx, target_idx in facial_area_obj:\n",
    "    source = landmarks.landmark[source_idx]\n",
    "    target = landmarks.landmark[target_idx]\n",
    "\n",
    "    relative_source = (int(img.shape[1] * source.x), int(img.shape[0] * source.y))\n",
    "    relative_target = (int(img.shape[1] * target.x), int(img.shape[0] * target.y))\n",
    "\n",
    "    cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "    \n",
    "fig = plt.figure(figsize = (15, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c5171-ef43-44d2-8530-cdb96b3269ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = mp_face_mesh.FACEMESH_LEFT_IRIS\n",
    "df = pd.DataFrame(list( abc ), columns = [\"p1\", \"p2\"])\n",
    "\n",
    "routes_idx = []\n",
    "p1 = df.iloc[0][\"p1\"]\n",
    "p2 = df.iloc[0][\"p2\"]\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    \n",
    "    #print(p1, p2)\n",
    "    \n",
    "    obj = df[df[\"p1\"] == p2]\n",
    "    p1 = obj[\"p1\"].values[0]\n",
    "    p2 = obj[\"p2\"].values[0]\n",
    "    \n",
    "    route_idx = []\n",
    "    route_idx.append(p1)\n",
    "    route_idx.append(p2)\n",
    "    routes_idx.append(route_idx)\n",
    "\n",
    "routes = []\n",
    "\n",
    "print( routes_idx )\n",
    "#for source_idx, target_idx in mp_face_mesh.FACEMESH_FACE_OVAL:\n",
    "for source_idx, target_idx in routes_idx:\n",
    "    print( source_idx, target_idx )\n",
    "    source = landmarks.landmark[source_idx]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d7822-b802-4d5a-a0a5-b35189bbf36d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "landmarks.landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3a1ba-4a00-4811-9f03-9c38ff7883fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_landmark(img_base, facial_area_name, facial_area_obj):\n",
    "    \n",
    "#     print(facial_area_name, \":\")\n",
    "    \n",
    "#     img = img_base.copy()\n",
    "    \n",
    "#     for source_idx, target_idx in facial_area_obj:\n",
    "#         source = landmarks.landmark[source_idx]\n",
    "#         target = landmarks.landmark[target_idx]\n",
    "\n",
    "#         relative_source = (int(img.shape[1] * source.x), int(img.shape[0] * source.y))\n",
    "#         relative_target = (int(img.shape[1] * target.x), int(img.shape[0] * target.y))\n",
    "\n",
    "#         cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "    \n",
    "#     fig = plt.figure(figsize = (15, 15))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "path = r\"Img/test.jpg\"\n",
    "img = load_image( path )\n",
    "\n",
    "\n",
    "def find_imp_cord( img):\n",
    "    faceModule = mediapipe.solutions.face_mesh\n",
    "    face_mesh = faceModule.FaceMesh(static_image_mode=True)\n",
    "    results = face_mesh.process(img )\n",
    "    landmarks = results.multi_face_landmarks[0]\n",
    "\n",
    "    def getLandmarkCenter(facial_area_obj):\n",
    "        lmrk_routes = []\n",
    "        for source_idx, target_idx in facial_area_obj:\n",
    "            # print(source_idx, target_idx)\n",
    "            source = landmarks.landmark[source_idx]\n",
    "            target = landmarks.landmark[target_idx]\n",
    "        \n",
    "            relative_source = (int(img.shape[1] * source.x), int(img.shape[0] * source.y))\n",
    "            relative_target = (int(img.shape[1] * target.x), int(img.shape[0] * target.y))\n",
    "            \n",
    "            lmrk_routes.append(relative_source)\n",
    "            lmrk_routes.append(relative_target)\n",
    "        \n",
    "            cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "            \n",
    "        lmrk_min_x_pt = min(lmrk_routes, key=lambda x: x[0])\n",
    "        lmrk_max_x_pt = max(lmrk_routes, key=lambda x: x[0])\n",
    "        lmrk_min_y_pt = min(lmrk_routes, key=lambda x: x[1])\n",
    "        lmrk_max_y_pt = max(lmrk_routes, key=lambda x: x[1])\n",
    "        \n",
    "        center = (int((lmrk_min_x_pt[0]+lmrk_max_x_pt[0])/2.0), int((lmrk_min_y_pt[1]+lmrk_max_y_pt[1])/2.0))\n",
    "        return center\n",
    "\n",
    "    facial_area_obj = faceModule.FACEMESH_RIGHT_EYE\n",
    "    right_eye_center = getLandmarkCenter(facial_area_obj)\n",
    "    facial_area_obj = faceModule.FACEMESH_LEFT_EYE\n",
    "    left_eye_center = getLandmarkCenter(facial_area_obj)\n",
    "    return right_eye_center, left_eye_center\n",
    "cv2.circle(img, center, 2, (255, 255, 255), thickness=2)\n",
    "\n",
    "# cv2.line(img, leye_min_x_pt, leye_max_x_pt, (255, 255, 255), thickness = 2)\n",
    "# cv2.line(img, leye_min_y_pt, leye_max_y_pt, (255, 255, 255), thickness = 2)\n",
    "\n",
    "# print(eye_routes)\n",
    "\n",
    "# cv2.line(img, (489, 537), (489,548), (255, 255, 255), thickness = 2)\n",
    "# cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "# cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "# cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "\n",
    "fig = plt.figure(figsize = (15, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# plot_landmark(img, 'Tesselation', facial_area_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e82527-7a34-4aa8-ad66-1bd9dba876da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(routes, columns = [\"p1\", \"p2\"])\n",
    "x1,y1,x2,y2 = min(df1['p1']), min(df1['p2']), max(df1['p1']), max(df1['p2']) \n",
    "print(x1,y1,x2,y2)\n",
    "# img1 = out[y1:y2, x1:x2]\n",
    "# img1 = img[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e823e-417d-443b-aa56-9da618dea808",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e099509-c41e-4595-b25c-707bfe8ff91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb5265-2a70-4691-9565-0c4a40f7f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"Img/test.jpg\"\n",
    "img = load_image( path )\n",
    "\n",
    "mp_face_mesh = mediapipe.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
    "results = face_mesh.process( img )\n",
    "\n",
    "landmarks = results.multi_face_landmarks[0]\n",
    "\n",
    "abc = mp_face_mesh.FACEMESH_FACE_OVAL\n",
    "df = pd.DataFrame(list( abc ), columns = [\"p1\", \"p2\"])\n",
    "\n",
    "routes_idx = []\n",
    "p1 = df.iloc[0][\"p1\"]\n",
    "p2 = df.iloc[0][\"p2\"]\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    obj = df[df[\"p1\"] == p2]\n",
    "    p1 = obj[\"p1\"].values[0]\n",
    "    p2 = obj[\"p2\"].values[0]\n",
    "    route_idx = []\n",
    "    route_idx.append(p1)\n",
    "    route_idx.append(p2)\n",
    "    routes_idx.append(route_idx)\n",
    "\n",
    "routes = []\n",
    "for source_idx, target_idx in routes_idx:\n",
    "    source = landmarks.landmark[source_idx]\n",
    "    target = landmarks.landmark[target_idx]\n",
    "        \n",
    "    relative_source = (int(img.shape[1] * source.x), int(img.shape[0] * source.y))\n",
    "    relative_target = (int(img.shape[1] * target.x), int(img.shape[0] * target.y))\n",
    "\n",
    "    cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "    print(relative_source, relative_target)\n",
    "    routes.append(relative_source)\n",
    "    routes.append(relative_target)\n",
    "    break\n",
    "\n",
    "fig = plt.figure(figsize = (7,7))\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "# mask = np.zeros((img.shape[0], img.shape[1]))\n",
    "# mask = cv2.fillConvexPoly(mask, np.array(routes), 1)\n",
    "# mask = mask.astype(bool)\n",
    " \n",
    "# out = np.zeros_like(img)\n",
    "# out[mask] = img[mask]\n",
    "\n",
    "# df1 = pd.DataFrame(routes, columns = [\"p1\", \"p2\"])\n",
    "# x1,y1,x2,y2 = min(df1['p1']), min(df1['p2']), max(df1['p1']), max(df1['p2']) \n",
    "# # img1 = out[y1:y2, x1:x2]\n",
    "# img1 = img[y1:y2, x1:x2]\n",
    "\n",
    "# fig = plt.figure(figsize = (7,7))\n",
    "# plt.axis('off')\n",
    "# plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cababc2-2040-4950-bdd4-a2e2b274e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf2d4e-0ef9-400b-8b5b-8d7461866843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2094c2b-3338-4080-bc4a-ab45a96dbe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(routes)\n",
    "df = pd.DataFrame(routes, columns = [\"p1\", \"p2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c7ac2-0b4b-4717-84d7-ba28d292ea2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12c1144-4dc6-4675-9729-d67996ffde7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a2ec8-56d3-4d9c-a189-931ba27c49cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [y1:y2, x1:x2]\n",
    "img1 = img[y1:y2, x1:x2]\n",
    "# img1 = img[210:567 , 407:715]\n",
    "# img1 = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81f6cd5-2a80-4eb2-81e1-4a42fec0376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e8049-9df3-41ec-86f6-f95cbfe0f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [y:y+h, x:x+w]\n",
    "# img1 = img[715:567 , 407:210]\n",
    "img1 = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859ae1f-74e5-4258-9bea-5f7602cf42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (7,7))\n",
    "plt.axis('off')\n",
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36852b6b-6a5d-4fdf-95ff-138554397dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(dic, i):\n",
    "    image = plt.imread(dic[\"filename\"])\n",
    "    x0 = dic[\"annotations\"][i][\"x\"]\n",
    "    y0 = dic[\"annotations\"][i][\"y\"]\n",
    "    width = dic[\"annotations\"][i][\"width\"]\n",
    "    height = dic[\"annotations\"][i][\"height\"]\n",
    "    return \n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "ax.imshow(plt.imread(mydic[\"filename\"]))\n",
    "\n",
    "ax1 = fig.add_subplot(222)\n",
    "ax1.imshow(crop(mydic, 0))\n",
    "\n",
    "ax2 = fig.add_subplot(224)\n",
    "ax2.imshow(crop(mydic, 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765e702-32ae-462a-8ca5-0ce8b97ae561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388b055c-53a8-4ea9-95fa-59a2255a59c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5166e6ca-6eb9-4079-95fe-84417547c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faceModule = mediapipe.solutions.face_mesh\n",
    "face_mesh = faceModule.FaceMesh(static_image_mode=True)\n",
    "\n",
    "path = r\"Img/test.jpg\"\n",
    "img_obj = load_image( path )\n",
    "\n",
    "img = img_obj.copy()\n",
    "\n",
    "results = face_mesh.process( img_obj )\n",
    "landmarks = results.multi_face_landmarks[0]\n",
    "\n",
    "facial_area = \"Tesselation\"\n",
    "\n",
    "facial_area_obj = faceModule.FACEMESH_TESSELATION\n",
    "rs, rt = [], []\n",
    "for source_idx, target_idx in facial_area_obj:\n",
    "    source = landmarks.landmark[source_idx]\n",
    "    target = landmarks.landmark[target_idx]\n",
    "\n",
    "    relative_source = (int(img.shape[1] * source.x), int(img.shape[0] * source.y))\n",
    "    relative_target = (int(img.shape[1] * target.x), int(img.shape[0] * target.y))\n",
    "    rs.append(relative_target)\n",
    "    rt.append(relative_target)\n",
    "    cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "    \n",
    "\n",
    "fig = plt.figure(figsize = (15, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow( img )\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# imp_cord, img_ = get_imp_cord(img_obj )\n",
    "# fig = plt.figure(figsize = (10,10))\n",
    "# plt.axis('off')\n",
    "# plt.imshow(img_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ef3fb-0af7-447a-a5fb-531c4c0b4faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f9643-935b-4233-8c1a-30230db1e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(list(mp_face_mesh.FACEMESH_FACE_OVAL), columns = [\"p1\", \"p2\"])\n",
    "routes_idx = []\n",
    "p1 = df.iloc[0][\"p1\"]\n",
    "p2 = df.iloc[0][\"p2\"]\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    \n",
    "    #print(p1, p2)\n",
    "    \n",
    "    obj = df[df[\"p1\"] == p2]\n",
    "    p1 = obj[\"p1\"].values[0]\n",
    "    p2 = obj[\"p2\"].values[0]\n",
    "    \n",
    "    route_idx = []\n",
    "    route_idx.append(p1)\n",
    "    route_idx.append(p2)\n",
    "    routes_idx.append(route_idx)\n",
    "\n",
    "routes = []\n",
    "\n",
    "#for source_idx, target_idx in mp_face_mesh.FACEMESH_FACE_OVAL:\n",
    "for source_idx, target_idx in routes_idx:\n",
    "    \n",
    "    source = landmarks.landmark[source_idx]\n",
    "    target = landmarks.landmark[target_idx]\n",
    "        \n",
    "    relative_source = (int(img.shape[1] * source.x), int(img.shape[0] * source.y))\n",
    "    relative_target = (int(img.shape[1] * target.x), int(img.shape[0] * target.y))\n",
    "\n",
    "    #cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "    \n",
    "    routes.append(relative_source)\n",
    "    routes.append(relative_target)\n",
    "\n",
    "mask = np.zeros((img.shape[0], img.shape[1]))\n",
    "mask = cv2.fillConvexPoly(mask, np.array(routes), 1)\n",
    "mask = mask.astype(bool)\n",
    " \n",
    "out = np.zeros_like(img)\n",
    "out[mask] = img[mask]\n",
    "\n",
    "fig = plt.figure(figsize = (15, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c09645-2f37-42be-a8ca-ddea566b0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "facial_areas = {\n",
    "    'Contours': faceModule.FACEMESH_CONTOURS\n",
    "    , 'Lips': faceModule.FACEMESH_LIPS\n",
    "    , 'Face_oval': faceModule.FACEMESH_FACE_OVAL\n",
    "    , 'Left_eye': faceModule.FACEMESH_LEFT_EYE\n",
    "    , 'Left_eye_brow': faceModule.FACEMESH_LEFT_EYEBROW\n",
    "    , 'Right_eye': faceModule.FACEMESH_RIGHT_EYE\n",
    "    , 'Right_eye_brow': faceModule.FACEMESH_RIGHT_EYEBROW\n",
    "    , 'Tesselation': faceModule.FACEMESH_TESSELATION\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19da6d8-ea23-489f-94fd-60bff3b381b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceModule = mediapipe.solutions.face_mesh\n",
    "face_mesh = faceModule.FaceMesh(static_image_mode=True)\n",
    "\n",
    "img_proc = cv2.cvtColor(img_base, cv2.COLOR_BGR2RGB)\n",
    "results = face_mesh.process( img_proc )\n",
    "landmarks = results.multi_face_landmarks[0]\n",
    "\n",
    "facial_area = \"Tesselation\"\n",
    "\n",
    "facial_area_obj = faceModule.FACEMESH_TESSELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d4a09-6f80-4496-80b5-773ce9e2d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image( path ):\n",
    "    img_base = cv2.imread( path )\n",
    "    img_proc = cv2.cvtColor(img_base, cv2.COLOR_BGR2RGB)\n",
    "    return img_proc\n",
    "\n",
    "def get_imp_cord(img ):\n",
    "    results = face_detector.process(img)\n",
    "    imp_cord = {}\n",
    "    if results.detections:\n",
    "        if len(results.detections)==1:\n",
    "            print(\"Selected Number of Faces:\", len(results.detections))\n",
    "            for face in results.detections:\n",
    "                confidence = face.score[0]\n",
    "                print(\"Face confidence:\", confidence)\n",
    "                bounding_box = face.location_data.relative_bounding_box\n",
    "    \n",
    "                x = int(bounding_box.xmin * img.shape[1])\n",
    "                w = int(bounding_box.width * img.shape[1])\n",
    "                y = int(bounding_box.ymin * img.shape[0])\n",
    "                h = int(bounding_box.height * img.shape[0])\n",
    "                \n",
    "            # cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 255), thickness = 2)\n",
    "    \n",
    "            landmarks = face.location_data.relative_keypoints\n",
    "         \n",
    "            right_eye = (int(landmarks[0].x * img.shape[1]), int(landmarks[0].y * img.shape[0]))\n",
    "            left_eye = (int(landmarks[1].x * img.shape[1]), int(landmarks[1].y * img.shape[0]))\n",
    "            nose = (int(landmarks[2].x * img.shape[1]), int(landmarks[2].y * img.shape[0]))\n",
    "            mouth = (int(landmarks[3].x * img.shape[1]), int(landmarks[3].y * img.shape[0]))\n",
    "            # right_ear = (int(landmarks[4].x * img.shape[1]), int(landmarks[4].y * img.shape[0]))\n",
    "            # left_ear = (int(landmarks[5].x * img.shape[1]), int(landmarks[5].y * img.shape[0]))\n",
    "            imp_cord['R-EYE'] = right_eye\n",
    "            imp_cord['L-EYE'] = left_eye\n",
    "            # imp_cord['NOSE'] = nose\n",
    "            # imp_cord['mouth'] = mouth\n",
    "            \n",
    "            # cv2.circle(img, right_eye, 1, (255, 0, 0), -1)\n",
    "            # cv2.circle(img, left_eye, 1, (255, 0, 0), -1)\n",
    "            # cv2.circle(img, nose, 7, (255, 0, 0), -1)\n",
    "            # cv2.circle(img, mouth, 7, (255, 0, 0), -1)\n",
    "        else:\n",
    "            print(\"more than one face\")\n",
    "    else:\n",
    "        print(\"No Detection\")\n",
    "    return imp_cord, img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d389b-7321-4a0e-ba6a-54932f40cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_detection = mediapipe.solutions.face_detection\n",
    "face_detector =  mp_face_detection.FaceDetection( min_detection_confidence = 0.6)\n",
    "\n",
    "path = r\"Img/test1.jpg\"\n",
    "img_obj = load_image( path )\n",
    "\n",
    "imp_cord, img_ = get_imp_cord(img_obj )\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "plt.axis('off')\n",
    "plt.imshow(img_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e300ae6-263f-48d9-bc48-ffbda4582711",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eye_1 = imp_cord['L-EYE']\n",
    "eye_2 = imp_cord['R-EYE']\n",
    "\n",
    "#--------------------\n",
    "#decide left and right eye\n",
    "if eye_1[0] < eye_2[0]:\n",
    "    left_eye = eye_1\n",
    "    right_eye = eye_2\n",
    "else:\n",
    "    left_eye = eye_2\n",
    "    right_eye = eye_1\n",
    "\n",
    "left_eye_x = left_eye[0]\n",
    "left_eye_y = left_eye[1]\n",
    "right_eye_x = right_eye[0]\n",
    "right_eye_y =right_eye[1]\n",
    "\n",
    "#----------------------\n",
    "#find rotation direction\n",
    "if left_eye_y > right_eye_y:\n",
    "    point_3rd = (right_eye_x, left_eye_y)\n",
    "    direction = -1 #rotate same direction to clock\n",
    "    print(\"rotate to clock direction\")\n",
    "else:\n",
    "    point_3rd = (left_eye_x, right_eye_y)\n",
    "    direction = 1 #rotate inverse direction of clock\n",
    "    print(\"rotate to inverse clock direction\")\n",
    "\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "\tx1 = a[0]; y1 = a[1]\n",
    "\tx2 = b[0]; y2 = b[1]\n",
    "\n",
    "\treturn math.sqrt(((x2 - x1) * (x2 - x1)) + ((y2 - y1) * (y2 - y1)))\n",
    "    \n",
    "#----------------------\n",
    "#find angle\n",
    "a = euclidean_distance(left_eye, point_3rd) # math.dist(left_eye, point_3rd)\n",
    "b = euclidean_distance(right_eye, point_3rd)\n",
    "c = euclidean_distance(right_eye, left_eye)\n",
    "\n",
    "cos_a = (b*b + c*c - a*a)/(2*b*c)\n",
    "#print(\"cos(a) = \", cos_a)\n",
    "angle = np.arccos(cos_a)\n",
    "#print(\"angle: \", angle,\" in radian\")\n",
    "\n",
    "angle = (angle * 180) / math.pi\n",
    "# print(\"angle: \", angle,\" in degree\")\n",
    "\n",
    "if direction == -1:\n",
    "    angle = 90 - angle\n",
    "\n",
    "print(\"angle: \", angle,\" in degree\")\n",
    "\n",
    "\n",
    "#--------------------\n",
    "#rotate image\n",
    "\n",
    "new_img = Image.fromarray(img_obj)\n",
    "new_img = np.array(new_img.rotate(direction * angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee055279-6248-4b2f-84d4-a3b9c9638bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b01952-1281-4c59-950d-610bdaf408f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5e6f2-8a42-45f3-9b54-06f7a0fb474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "#find rotation direction\n",
    "if left_eye_y > right_eye_y:\n",
    "    point_3rd = (right_eye_x, left_eye_y)\n",
    "    direction = -1 #rotate same direction to clock\n",
    "    print(\"rotate to clock direction\")\n",
    "else:\n",
    "    point_3rd = (left_eye_x, right_eye_y)\n",
    "    direction = 1 #rotate inverse direction of clock\n",
    "    print(\"rotate to inverse clock direction\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035a9e1-c9a3-43b7-b65e-00bf372d8aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "\tx1 = a[0]; y1 = a[1]\n",
    "\tx2 = b[0]; y2 = b[1]\n",
    "\n",
    "\treturn math.sqrt(((x2 - x1) * (x2 - x1)) + ((y2 - y1) * (y2 - y1)))\n",
    "    \n",
    "#----------------------\n",
    "#find angle\n",
    "a = euclidean_distance(left_eye, point_3rd) # math.dist(left_eye, point_3rd)\n",
    "b = euclidean_distance(right_eye, point_3rd)\n",
    "c = euclidean_distance(right_eye, left_eye)\n",
    "\n",
    "cos_a = (b*b + c*c - a*a)/(2*b*c)\n",
    "#print(\"cos(a) = \", cos_a)\n",
    "angle = np.arccos(cos_a)\n",
    "#print(\"angle: \", angle,\" in radian\")\n",
    "\n",
    "angle = (angle * 180) / math.pi\n",
    "# print(\"angle: \", angle,\" in degree\")\n",
    "\n",
    "if direction == -1:\n",
    "    angle = 90 - angle\n",
    "\n",
    "print(\"angle: \", angle,\" in degree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340d3fb-4dba-4dff-a386-aed7a97cb8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------\n",
    "#rotate image\n",
    "\n",
    "new_img = Image.fromarray(img_obj)\n",
    "new_img = np.array(new_img.rotate(direction * angle))\n",
    "# new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afee31-f918-480a-b6b2-2b7fe60608a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e35dd-21a2-4908-8fa8-919996cb851b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06647c8f-b717-461c-a6e8-108c2e2e281c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_landmark(fm_results, fd_results, img, landmarks, facial_area_obj):\n",
    "    \n",
    "    if fd_results.detections:\n",
    "        for face in fd_results.detections:\n",
    "            fd_landmarks = face.location_data.relative_keypoints\n",
    "            confidence = face.score\n",
    "            bounding_box = face.location_data.relative_bounding_box\n",
    "             \n",
    "            x = int(bounding_box.xmin * img.shape[1])\n",
    "            w = int(bounding_box.width * img.shape[1])\n",
    "            y = int(bounding_box.ymin * img.shape[0])\n",
    "            h = int(bounding_box.height * img.shape[0])\n",
    "             \n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 255), thickness = 2)\n",
    "            \n",
    "            eye = (int(fd_landmarks[1].x * img.shape[1]), int(fd_landmarks[1].y * img.shape[0]))\n",
    "            eye = (int(fd_landmarks[1].x * img.shape[1]), int(fd_landmarks[1].y * img.shape[0]))\n",
    "            cv2.circle(img, eye, 3, (0, 0, 255), -1)\n",
    "\n",
    "    fm_landmarks = fm_results.multi_face_landmarks[0]\n",
    "    for source_idx, target_idx in facial_area_obj:\n",
    "        source = fm_landmarks.landmark[source_idx]\n",
    "        target = fm_landmarks.landmark[target_idx]\n",
    "\n",
    "        relative_source = (int(img.shape[1] * source.x), int(img.shape[0] * source.y))\n",
    "        relative_target = (int(img.shape[1] * target.x), int(img.shape[0] * target.y))\n",
    "\n",
    "        cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "    \n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def load_image( path ):\n",
    "    img_base = cv2.imread( path )\n",
    "    img_proc = cv2.cvtColor(img_base, cv2.COLOR_BGR2RGB)\n",
    "    return img_proc\n",
    "    \n",
    "path = r\"Img/test1.jpg\"\n",
    "img = load_image( path )\n",
    "\n",
    "faceModule = mediapipe.solutions.face_mesh\n",
    "face_mesh = faceModule.FaceMesh(static_image_mode=True)\n",
    "\n",
    "mp_face_detection = mediapipe.solutions.face_detection\n",
    "face_detector =  mp_face_detection.FaceDetection( min_detection_confidence = 0.6)\n",
    "\n",
    "fm_results = face_mesh.process(img)\n",
    "fd_results = face_detector.process(img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "facial_area_obj = faceModule.FACEMESH_FACE_OVAL\n",
    "facial_area_obj = faceModule.FACEMESH_IRISES\n",
    "plot_landmark(fm_results, fd_results, img, landmarks, facial_area_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed4f49-a325-4404-8bec-a9c33574f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmark_coords(fm_results, img, landmarks, facial_area_obj):\n",
    "    \n",
    "    fm_landmarks = fm_results.multi_face_landmarks[0]\n",
    "    for source_idx, target_idx in facial_area_obj:\n",
    "        source = fm_landmarks.landmark[source_idx]\n",
    "        target = fm_landmarks.landmark[target_idx]\n",
    "\n",
    "        relative_source = (int(img.shape[1] * source.x), int(img.shape[0] * source.y))\n",
    "        relative_target = (int(img.shape[1] * target.x), int(img.shape[0] * target.y))\n",
    "        print(relative_source, relative_target)\n",
    "\n",
    "        cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "    \n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136cf06e-6297-47e7-8b09-61e3eec309b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "facial_area_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d6990-dd5c-4b06-ae0c-c2c56d6ba0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_results = face_mesh.process(img)\n",
    "# facial_area_obj = faceModule.FACEMESH_FACE_OVAL\n",
    "facial_area_obj = faceModule.FACEMESH_IRISES\n",
    "landmark_coords(fm_results, img, landmarks, facial_area_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63899806-3cd5-4756-8f7f-842e4e1bb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7b543-9315-4961-b79c-df648ec32d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def display_image( img_obj ):\n",
    "    plt.imshow( img_obj )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac29e2-a601-4c95-8328-5ff7502e1602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = r\"Img/girl.jpg\"\n",
    "path = r\"Img/tm.jpg\"\n",
    "path = r\"Img/yr1.jpg\"\n",
    "path = r\"Img/r11.jpg\"\n",
    "\n",
    "img = load_image( path )\n",
    "\n",
    "mp_face_detection = mediapipe.solutions.face_detection\n",
    "face_detector =  mp_face_detection.FaceDetection( min_detection_confidence = 0.6)\n",
    "\n",
    "results = face_detector.process( img )\n",
    "print( len( results.detections ) )\n",
    "# confidence = face.score\n",
    "display_image( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa28bbcf-8c04-4a3d-9a9e-5d7051484630",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd44dd0e-a8d8-47f2-936a-2be5b1e26f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh.FACEMESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af45f7d-d26c-430d-b94d-2ab4b83d8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(mp_face_mesh.FACEMESH_IRISES), columns = [\"p1\", \"p2\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9cfdb9-7b8b-4122-bda0-213f3e2b3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"Img/r11.jpg\"\n",
    "\n",
    "img = load_image( path )\n",
    "\n",
    "mp_face_mesh = mediapipe.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
    "results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "landmarks = results.multi_face_landmarks[0]\n",
    "landmarks = results.\n",
    "\n",
    "df = pd.DataFrame(list(mp_face_mesh.FACEMESH_FACE_OVAL), columns = [\"p1\", \"p2\"])\n",
    "routes_idx = []\n",
    "p1 = df.iloc[0][\"p1\"]\n",
    "p2 = df.iloc[0][\"p2\"]\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    \n",
    "    #print(p1, p2)\n",
    "    \n",
    "    obj = df[df[\"p1\"] == p2]\n",
    "    p1 = obj[\"p1\"].values[0]\n",
    "    p2 = obj[\"p2\"].values[0]\n",
    "    \n",
    "    route_idx = []\n",
    "    route_idx.append(p1)\n",
    "    route_idx.append(p2)\n",
    "    routes_idx.append(route_idx)\n",
    "\n",
    "routes = []\n",
    "\n",
    "#for source_idx, target_idx in mp_face_mesh.FACEMESH_FACE_OVAL:\n",
    "for source_idx, target_idx in routes_idx:\n",
    "    \n",
    "    source = landmarks.landmark[source_idx]\n",
    "    target = landmarks.landmark[target_idx]\n",
    "        \n",
    "    relative_source = (int(img.shape[1] * source.x), int(img.shape[0] * source.y))\n",
    "    relative_target = (int(img.shape[1] * target.x), int(img.shape[0] * target.y))\n",
    "\n",
    "    #cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "    \n",
    "    routes.append(relative_source)\n",
    "    routes.append(relative_target)\n",
    "\n",
    "mask = np.zeros((img.shape[0], img.shape[1]))\n",
    "mask = cv2.fillConvexPoly(mask, np.array(routes), 1)\n",
    "mask = mask.astype(bool)\n",
    " \n",
    "out = np.zeros_like(img)\n",
    "out[mask] = img[mask]\n",
    "\n",
    "fig = plt.figure(figsize = (15, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa6a67a-0eb5-4084-b815-a736f99713b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8f2d8-c584-4958-bfdd-c49ec60f8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(routes)} landmark points available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda22bc-72be-4c05-a941-5a66b77d44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if results.detections:\n",
    "    for face in results.detections:\n",
    "        confidence = face.score\n",
    "        bounding_box = face.location_data.relative_bounding_box\n",
    "         \n",
    "        x = int(bounding_box.xmin * img.shape[1])\n",
    "        w = int(bounding_box.width * img.shape[1])\n",
    "        y = int(bounding_box.ymin * img.shape[0])\n",
    "        h = int(bounding_box.height * img.shape[0])\n",
    "         \n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 255), thickness = 2)\n",
    "\n",
    "landmarks = face.location_data.relative_keypoints\n",
    " \n",
    "right_eye = (int(landmarks[0].x * img.shape[1]), int(landmarks[0].y * img.shape[0]))\n",
    "left_eye = (int(landmarks[1].x * img.shape[1]), int(landmarks[1].y * img.shape[0]))\n",
    "nose = (int(landmarks[2].x * img.shape[1]), int(landmarks[2].y * img.shape[0]))\n",
    "mouth = (int(landmarks[3].x * img.shape[1]), int(landmarks[3].y * img.shape[0]))\n",
    "right_ear = (int(landmarks[4].x * img.shape[1]), int(landmarks[4].y * img.shape[0]))\n",
    "left_ear = (int(landmarks[5].x * img.shape[1]), int(landmarks[5].y * img.shape[0]))\n",
    " \n",
    "cv2.circle(img, right_eye, 15, (0, 0, 255), -1)\n",
    "cv2.circle(img, left_eye, 15, (0, 0, 255), -1)\n",
    "cv2.circle(img, nose, 15, (0, 0, 255), -1)\n",
    "cv2.circle(img, mouth, 15, (0, 0, 255), -1)\n",
    "cv2.circle(img, right_ear, 15, (0, 0, 255), -1)\n",
    "cv2.circle(img, left_ear, 15, (0, 0, 255), -1)\n",
    "\n",
    "cv2.imshow(\"Original\",img)\n",
    "cv2.waitKey()\n",
    "#press any key to close the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a2d484-582d-4880-b53c-5034717e6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f11ad-4724-4cc1-b0cf-0674b41468b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\t\n",
    "import mediapipe\n",
    "import cv2\n",
    "#https://www.pexels.com/photo/portrait-photo-of-woman-in-white-crew-neck-shirt-8090149/\n",
    "img = cv2.imread(\"Img/girl.jpg\")\n",
    "# img = cv2.cvtColor(img_base, cv2.COLOR_BGR2RGB)\n",
    "mp_face_detection = mediapipe.solutions.face_detection\n",
    "face_detector =  mp_face_detection.FaceDetection( min_detection_confidence = 0.6)\n",
    "\n",
    "results = face_detector.process(img)\n",
    "\n",
    "if results.detections:\n",
    "    for face in results.detections:\n",
    "        confidence = face.score\n",
    "        bounding_box = face.location_data.relative_bounding_box\n",
    "         \n",
    "        x = int(bounding_box.xmin * img.shape[1])\n",
    "        w = int(bounding_box.width * img.shape[1])\n",
    "        y = int(bounding_box.ymin * img.shape[0])\n",
    "        h = int(bounding_box.height * img.shape[0])\n",
    "         \n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 255), thickness = 2)\n",
    "\n",
    "landmarks = face.location_data.relative_keypoints\n",
    " \n",
    "right_eye = (int(landmarks[0].x * img.shape[1]), int(landmarks[0].y * img.shape[0]))\n",
    "left_eye = (int(landmarks[1].x * img.shape[1]), int(landmarks[1].y * img.shape[0]))\n",
    "nose = (int(landmarks[2].x * img.shape[1]), int(landmarks[2].y * img.shape[0]))\n",
    "mouth = (int(landmarks[3].x * img.shape[1]), int(landmarks[3].y * img.shape[0]))\n",
    "right_ear = (int(landmarks[4].x * img.shape[1]), int(landmarks[4].y * img.shape[0]))\n",
    "left_ear = (int(landmarks[5].x * img.shape[1]), int(landmarks[5].y * img.shape[0]))\n",
    " \n",
    "cv2.circle(img, right_eye, 3, (0, 0, 255), -1)\n",
    "cv2.circle(img, left_eye, 3, (0, 0, 255), -1)\n",
    "cv2.circle(img, nose, 4, (0, 0, 255), -1)\n",
    "cv2.circle(img, mouth, 5, (0, 0, 255), -1)\n",
    "\n",
    "# cv2.imshow(\"Original\",img)\n",
    "# cv2.waitKey()\n",
    "# #press any key to close the windows\n",
    "# cv2.destroyAllWindows()\n",
    "fig = plt.figure(figsize = (15, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2fe7fc-3ff6-4cdd-a3f4-f35ffc561c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Img/girl.jpg\"\n",
    "path = r\"Img/r11.jpg\"\n",
    "\n",
    "img_base = cv2.imread( path )\n",
    "img = img_base.copy()\n",
    "\n",
    "faceModule = mediapipe.solutions.face_mesh\n",
    "face_mesh = faceModule.FaceMesh(static_image_mode=True)\n",
    "\n",
    "img_proc = cv2.cvtColor(img_base, cv2.COLOR_BGR2RGB)\n",
    "results = face_mesh.process( img_proc )\n",
    "landmarks = results.multi_face_landmarks[0]\n",
    "\n",
    "facial_area = \"Tesselation\"\n",
    "\n",
    "facial_area_obj = faceModule.FACEMESH_TESSELATION\n",
    "\n",
    "for source_idx, target_idx in facial_area_obj:\n",
    "    source = landmarks.landmark[source_idx]\n",
    "    target = landmarks.landmark[target_idx]\n",
    "\n",
    "    relative_source = (int(img.shape[1] * source.x), int(img.shape[0] * source.y))\n",
    "    relative_target = (int(img.shape[1] * target.x), int(img.shape[0] * target.y))\n",
    "\n",
    "    cv2.line(img, relative_source, relative_target, (255, 255, 255), thickness = 2)\n",
    "\n",
    "fig = plt.figure(figsize = (15, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc9709f-8a27-4255-a26b-f45ffbd2c0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6679a5-2d73-43f2-93f5-993dfaff011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.waitKey()\n",
    "#press any key to close the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c7a67-c697-443f-9840-cf374ec4cdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
