{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Face Recognition"
      ],
      "metadata": {
        "id": "FVYMOgonYda5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# !pip list"
      ],
      "outputs": [],
      "metadata": {
        "id": "Kh8ukOKXYdbB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import face_recognition as fc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "metadata": {
        "id": "IMOk1wCUYdbE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data1 = \"Data/a11.png\"\n",
        "data2 = \"Data/a12.png\""
      ],
      "outputs": [],
      "metadata": {
        "id": "ksgUFekHYdbH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "img = cv2.imread(data1, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "cv2.imshow('image',img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "outputs": [],
      "metadata": {
        "id": "yvL5U_ExYdbI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "img = cv2.imread(data1 )\n",
        "imgR = cv2.resize(img, (0, 0), None, 0.50, 0.50)\n",
        "imgG = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "imgS = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "cv2.imshow('Img',img)\n",
        "cv2.imshow(\"ImgR\", imgR)\n",
        "cv2.imshow(\"ImgG\", imgG)\n",
        "cv2.imshow('ImgS',imgS)\n",
        "# cv2.imwrite(r'AttendanceImg\\a.jpg',img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "3UNjo7OKYdbJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data0 = \"Data/a11.png\"\n",
        "image = fc.load_image_file(data0)\n",
        "face_locations = fc.face_locations(image)\n",
        "face_locations\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(32, 487, 94, 425), (58, 121, 94, 85), (149, 494, 211, 432)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "metadata": {
        "id": "5vGMLV4hYdbK",
        "outputId": "1f42be20-3f06-4510-a79e-5556bb11d4d2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data0 = \"Data/a13.png\"\n",
        "image = fc.load_image_file(data0)\n",
        "face_locations = fc.face_locations(image)\n",
        "face_locations\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "id": "I4NU70s3YdbM",
        "outputId": "6e90b4f9-6b1f-44ed-f5d7-f0e8c54409a8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def detectFace(path):\n",
        "    img = fc.load_image_file(path)\n",
        "    height, width, channels = img.shape\n",
        "    imgtrain = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    faceLoc = fc.face_locations(imgtrain)  # find face location : top, right, bottom, left\n",
        "    if len(faceLoc)!=0:\n",
        "        for face in faceLoc:\n",
        "            #print(face)\n",
        "            top, right, bottom, left = face\n",
        "            cv2.rectangle(imgtrain,(left, top), (right, bottom), (255,0,255), 2)\n",
        "        return imgtrain\n",
        "    cv2.rectangle(imgtrain, (width//8, height//9-15), (width//8 + 355, height//9 + 15), (255,100,0), -1)\n",
        "    cv2.putText(imgtrain,\"No Faces detcted\", (width//8, height//9), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, color = (0, 0, 0), thickness= 1)\n",
        "    return imgtrain\n",
        "\n",
        "data2 = \"Data/a14.png\"\n",
        "# detectFace(data2)\n",
        "img12 = detectFace(data2)\n",
        "cv2.imshow('Training Image',img12)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "outputs": [],
      "metadata": {
        "id": "4dyKOExFYdbO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def faceCrop(path):\n",
        "    img = fc.load_image_file(path)\n",
        "    height, width, channels = img.shape\n",
        "    imgtrain = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    faceLoc = fc.face_locations(imgtrain)  # find face location : top, right, bottom, left\n",
        "    if len(faceLoc)!=0:\n",
        "        for i, face in enumerate(faceLoc):\n",
        "            top, right, bottom, left = face\n",
        "            cv2.rectangle(imgtrain,(left, top), (right, bottom), (255,0,255), 2)\n",
        "            img1= imgtrain[top:bottom, left:right]\n",
        "            cv2.imwrite(r'Face_{}.png'.format(i+1), img1)\n",
        "    else:\n",
        "        print(\"No Face Detected.........!\")\n",
        "\n",
        "data2 = r\"Data/KnownFaces/a12.png\"\n",
        "faceCrop(data2)"
      ],
      "outputs": [],
      "metadata": {
        "id": "H12GmXg4YdbP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data0 = \"Data/a12.png\"\n",
        "image = fc.load_image_file(data0)\n",
        "# Or you could get face encodings for each face in the image:\n",
        "list_of_face_encodings = fc.face_encodings(image)\n",
        "# len(list_of_face_encodings)\n",
        "known_face_encodings = list_of_face_encodings\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "LsGWd27eYdbQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data0 = \"Data/2222.png\"\n",
        "image = fc.load_image_file(data0)\n",
        "# Or you could get face encodings for each face in the image:\n",
        "list_of_face_encodings = fc.face_encodings(image)\n",
        "# len(list_of_face_encodings)\n",
        "a_single_unknown_face_encoding = list_of_face_encodings[0]\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "HQs03AIbYdbR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# results is an array of True/False telling if the unknown face matched anyone in the known_faces array\n",
        "results = fc.compare_faces([known_face_encodings], a_single_unknown_face_encoding)\n",
        "results"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True])]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "metadata": {
        "id": "cJnbU7nuYdbR",
        "outputId": "4cec3356-6f12-4acf-f0ce-f314e2f267b1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "faceDis = fc.face_distance([known_face_encodings],a_single_unknown_face_encoding)  # Accuracy\n",
        "faceDis"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.68802047e-04, 5.85913658e-04, 5.75453043e-04, 2.34626047e-03,\n",
              "        1.81951933e-03, 5.14905900e-04, 2.47642770e-03, 1.93963572e-03,\n",
              "        1.79462135e-03, 2.88105011e-03, 9.18120146e-04, 2.28585862e-03,\n",
              "        3.00186872e-03, 5.20423055e-04, 1.44384801e-04, 1.13361329e-03,\n",
              "        7.43910670e-04, 2.68392265e-03, 2.01796368e-03, 2.50231475e-03,\n",
              "        1.00528076e-03, 1.44566409e-03, 3.50566581e-04, 2.48249434e-03,\n",
              "        5.21153212e-04, 3.05920839e-04, 1.02730095e-03, 3.50143760e-03,\n",
              "        9.98470932e-04, 5.03844768e-03, 2.37319618e-03, 3.11497599e-04,\n",
              "        2.13976204e-03, 4.48055565e-04, 1.47960708e-03, 4.47779894e-06,\n",
              "        1.52552873e-03, 1.47467665e-03, 1.86866522e-03, 8.40630382e-05,\n",
              "        4.05706465e-03, 7.21276738e-04, 6.21193089e-03, 2.33229995e-03,\n",
              "        6.82622194e-05, 7.17416406e-05, 4.09676693e-03, 2.65510008e-03,\n",
              "        8.56675208e-04, 4.99129295e-03, 4.16851044e-03, 3.63570452e-03,\n",
              "        1.24847144e-03, 1.15764886e-03, 3.71955335e-03, 5.39075583e-03,\n",
              "        3.11601907e-05, 1.47305802e-03, 1.10885501e-03, 1.87015533e-03,\n",
              "        1.62610225e-03, 7.54236430e-03, 1.69179589e-03, 3.91425192e-03,\n",
              "        6.69561327e-03, 2.51681358e-03, 1.22994930e-03, 8.20726156e-04,\n",
              "        3.68535519e-03, 1.07884407e-03, 5.51948790e-04, 2.46688724e-04,\n",
              "        4.47738916e-04, 1.51987374e-03, 2.13906169e-04, 4.26024199e-05,\n",
              "        2.43282318e-03, 7.17356801e-03, 4.14296240e-03, 3.19483131e-03,\n",
              "        3.64102423e-03, 2.93064862e-04, 3.52432579e-03, 4.38169390e-03,\n",
              "        1.76602602e-03, 4.81978059e-04, 9.83394682e-04, 4.41476703e-04,\n",
              "        1.38751417e-03, 2.75710225e-03, 1.36937946e-03, 2.43702531e-03,\n",
              "        1.70512125e-03, 1.07495300e-03, 3.48584354e-03, 2.09461153e-03,\n",
              "        9.98035073e-04, 3.00255511e-03, 7.45777041e-03, 1.08852424e-03,\n",
              "        6.17489219e-04, 4.27541137e-03, 1.52845122e-03, 1.97216868e-05,\n",
              "        1.42034888e-03, 3.17393243e-03, 2.52573751e-03, 2.12912261e-03,\n",
              "        3.54298204e-03, 4.22033668e-03, 2.45426595e-03, 6.94498420e-04,\n",
              "        2.05520540e-03, 9.62746143e-03, 5.31443208e-03, 2.29945779e-03,\n",
              "        8.65361653e-06, 2.77689099e-03, 6.74803555e-03, 1.45657733e-03,\n",
              "        1.20506622e-03, 9.95183364e-05, 8.39307904e-05, 1.15019083e-03,\n",
              "        1.97327137e-03, 4.27344814e-04, 1.19987130e-03, 1.76256523e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "metadata": {
        "id": "ZrxY5W1JYdbS",
        "outputId": "894791b2-a9ca-49f1-b2a8-e07da942a4ec"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "img = fc.load_image_file(data2)\n",
        "imgtrain = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "faceLoc = fc.face_locations(imgtrain)[0]  # find face location\n",
        "encode= fc.face_encodings(imgtrain)[0]  # face encode in 128 points\n",
        "\n",
        "cv2.rectangle(imgtrain,(faceLoc[3],faceLoc[0]), (faceLoc[1],faceLoc[2]), (255,0,255), 2)\n",
        "print(faceLoc) # top, right, bottom, left\n",
        "cv2.imshow('Training Image',imgtrain)\n",
        "# cv2.imshow('Test Image',imgTest)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(320, 617, 587, 349)\n"
          ]
        }
      ],
      "metadata": {
        "id": "4KhT9vlUYdbT",
        "outputId": "86fc2843-e140-4ab1-aa18-4c1f9d2815e8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "img = fc.load_image_file(data2)\n",
        "imgtrain = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "faceLoc = fc.face_locations(imgtrain)[0]  # find face location\n",
        "encode= fc.face_encodings(imgtrain)[0]  # face encode in 128 points\n",
        "\n",
        "cv2.rectangle(imgtrain,(faceLoc[3],faceLoc[0]), (faceLoc[1],faceLoc[2]), (255,0,255), 2)\n",
        "print(faceLoc) # top, right, bottom, left\n",
        "cv2.imshow('Training Image',imgtrain)\n",
        "# cv2.imshow('Test Image',imgTest)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "# # imgTest = face_recognition.load_image_file('AllSavesdImages/Elon-Test.jpg')\n",
        "# imgTest = face_recognition.load_image_file('AllSavesdImages/b1.jpg')\n",
        "# # imgTest = face_recognition.load_image_file('AllSavesdImages/bgates.jpg')\n",
        "# imgTest = cv2.cvtColor(imgTest,cv2.COLOR_BGR2RGB)\n",
        "# faceLocTest = face_recognition.face_locations(imgTest)[0]\n",
        "# encodeTest = face_recognition.face_encodings(imgTest)[0]\n",
        "# cv2.rectangle(imgTest,(faceLocTest[3],faceLocTest[0]),\n",
        "#               (faceLocTest[1],faceLocTest[2]),(255,0,255),2)\n",
        "\n",
        "# results = face_recognition.compare_faces([encodeTrain],encodeTest)  #True/False\n",
        "# faceDis = face_recognition.face_distance([encodeTrain],encodeTest)  # Accuracy\n",
        "# # print(results,faceDis)\n",
        "# cv2.putText(imgTest,f'{results} {round(faceDis[0],2)}',(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
        "\n",
        "# cv2.imshow('Training Image',imgtrain)\n",
        "# cv2.imshow('Test Image',imgTest)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()"
      ],
      "outputs": [],
      "metadata": {
        "id": "oZIZQ7PBYdbT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data0 = \"Data/a11.png\"\n",
        "image = fc.load_image_file(data0)\n",
        "# Or maybe find the facial features in the image\n",
        "face_landmarks_list = fc.face_landmarks(image)\n",
        "face_landmarks_list[0]['chin']"
      ],
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(435, 48),\n",
              " (435, 55),\n",
              " (435, 63),\n",
              " (435, 70),\n",
              " (436, 77),\n",
              " (439, 85),\n",
              " (441, 92),\n",
              " (445, 99),\n",
              " (452, 102),\n",
              " (460, 101),\n",
              " (468, 97),\n",
              " (476, 91),\n",
              " (483, 85),\n",
              " (488, 77),\n",
              " (491, 69),\n",
              " (493, 60),\n",
              " (494, 50)]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "metadata": {
        "id": "yPsN3xl9YdbV",
        "outputId": "5aa6815d-607d-4868-ee6a-2adb4ff82a32"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# cap = cv2.VideoCapture(0)\n",
        "# while True:\n",
        "#     success, img = cap.read()\n",
        "#     imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
        "#     imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#     facesCurFrame = face_recognition.face_locations(imgS)\n",
        "#     encodesCurFrame = face_recognition.face_encodings(imgS,facesCurFrame)\n",
        "#     for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):\n",
        "# #         print(encodeFace,faceLoc)\n",
        "#         y1,x2,y2,x1 = faceLoc\n",
        "#         y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4\n",
        "#         cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "#         cv2.imshow(\"FaceDetection\", img)\n",
        "#         cv2.imwrite(r'AttendanceImg\\a.jpg',img)\n",
        "#     key = cv2.waitKey(10)\n",
        "#     if key == 27:\n",
        "#         break\n",
        "# cap.release()\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()"
      ],
      "outputs": [],
      "metadata": {
        "id": "O7eY2F0vYdbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# # imgtrain = face_recognition.load_image_file('AllSavesdImages/Elon-Musk.jpg')\n",
        "# imgtrain = face_recognition.load_image_file('AllSavesdImages/a1.jpg')\n",
        "# imgtrain = cv2.cvtColor(imgtrain,cv2.COLOR_BGR2RGB)\n",
        "# faceLocTrain = face_recognition.face_locations(imgtrain)[0]  # find face location\n",
        "# encodeTrain = face_recognition.face_encodings(imgtrain)[0]  # face encode in 128 points\n",
        "# cv2.rectangle(imgtrain,(faceLocTrain[3],faceLocTrain[0]),\n",
        "#               (faceLocTrain[1],faceLocTrain[2]),(255,0,255),2)\n",
        "# #print(faceLoc) # top, right, bottom, left\n",
        "# # imgTest = face_recognition.load_image_file('AllSavesdImages/Elon-Test.jpg')\n",
        "# imgTest = face_recognition.load_image_file('AllSavesdImages/b1.jpg')\n",
        "# # imgTest = face_recognition.load_image_file('AllSavesdImages/bgates.jpg')\n",
        "# imgTest = cv2.cvtColor(imgTest,cv2.COLOR_BGR2RGB)\n",
        "# faceLocTest = face_recognition.face_locations(imgTest)[0]\n",
        "# encodeTest = face_recognition.face_encodings(imgTest)[0]\n",
        "# cv2.rectangle(imgTest,(faceLocTest[3],faceLocTest[0]),\n",
        "#               (faceLocTest[1],faceLocTest[2]),(255,0,255),2)\n",
        "\n",
        "# results = face_recognition.compare_faces([encodeTrain],encodeTest)  #True/False\n",
        "# faceDis = face_recognition.face_distance([encodeTrain],encodeTest)  # Accuracy\n",
        "# # print(results,faceDis)\n",
        "# cv2.putText(imgTest,f'{results} {round(faceDis[0],2)}',(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
        "\n",
        "# cv2.imshow('Training Image',imgtrain)\n",
        "# cv2.imshow('Test Image',imgTest)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()"
      ],
      "outputs": [],
      "metadata": {
        "id": "FRwUEjKjYdbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# import os.path\n",
        "# import time\n",
        "# import pandas as pd\n",
        "# from datetime import datetime\n",
        "\n",
        "\n",
        "# dt = datetime.now()\n",
        "# date = dt.strftime('%d-%m-%Y')\n",
        "# fname = \"Attendance-{}.csv\".format(date)\n",
        "\n",
        "# if not os.path.exists(fname):\n",
        "#     df = pd.DataFrame(columns= ['Name','Date','Time'])\n",
        "#     df.to_csv(fname,index=False)\n",
        "\n",
        "\n",
        "# def markAttendance(fname, name):\n",
        "#     df = pd.read_csv(fname)\n",
        "#     dt = datetime.now()\n",
        "#     date = dt.strftime('%d-%m-%Y')\n",
        "#     time = dt.strftime('%H:%M:%S')\n",
        "#     df1 = pd.DataFrame([[name,date,time]], columns= ['Name','Date','Time'])\n",
        "#     df = df.append(df1)\n",
        "#     df.to_csv(fname,index=False)\n",
        "\n",
        "# while True:\n",
        "#     print(\"Start System..!\")\n",
        "#     cap = cv2.VideoCapture(0)\n",
        "#     success, img = cap.read()\n",
        "#     #img = captureScreen()\n",
        "#     imgS = cv2.resize(img,(0,0),None,0.25,0.25)\n",
        "#     imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#     facesCurFrame = face_recognition.face_locations(imgS)\n",
        "#     encodesCurFrame = face_recognition.face_encodings(imgS,facesCurFrame)\n",
        "\n",
        "#     for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):\n",
        "#         matches = face_recognition.compare_faces(encodedListKnown,encodeFace)\n",
        "#         faceDis = face_recognition.face_distance(encodedListKnown,encodeFace)\n",
        "#         #print(faceDis)\n",
        "#         matchIndex = np.argmin(faceDis)\n",
        "#         if matches[matchIndex]:\n",
        "#             name = classNames[matchIndex].upper()\n",
        "#             print(name)\n",
        "#             y1,x2,y2,x1 = faceLoc\n",
        "#             y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4\n",
        "#             cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "#             cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
        "#             cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
        "#             markAttendance(fname, name)\n",
        "#             cv2.imshow('Webcam',img)\n",
        "#             dt = datetime.now()\n",
        "#             tm = dt.strftime('%H:%M:%S')\n",
        "#             fname2 = 'AttendanceImg\\\\'+name.replace(\" \",'-')+'-'+tm.replace(\":\",'')+'.png'\n",
        "#             print(fname2)\n",
        "#             cv2.imwrite(fname2,img)\n",
        "#             cap.release()\n",
        "#             cv2.waitKey(0)\n",
        "#             cv2.destroyAllWindows()\n",
        "#     print(\"Wait 5 Sec\")\n",
        "#     time.sleep(5)\n",
        "#     key = cv2.waitKey(0) & 0xFF\n",
        "#     if key == ord(\"q\"):\n",
        "#         print(\"Stop System...................\")\n",
        "#         break"
      ],
      "outputs": [],
      "metadata": {
        "id": "KXmxn4N2YdbX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01HY3vjnYqxe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('Venv': venv)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "interpreter": {
      "hash": "361c4d5ade972aba34638e093f48e27e23d4f1e9d45d7e1ce2e55a06c3f91735"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}